{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a82e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "import mlflow\n",
    "import numpy as np\n",
    "img_width, img_height = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7cac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'v_data/train'\n",
    "validation_data_dir = 'v_data/test'\n",
    "nb_train_samples =400\n",
    "nb_validation_samples = 100\n",
    "epochs = 20\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d8a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4665ba45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. / 255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,target_size=(img_width, img_height),batch_size=batch_size,\n",
    "class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1b90afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path=r\"Model\"\n",
    "saved_model_path1=r\"Model1\"\n",
    "saved_model_path2=r\"Model2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653684cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "reg_model_name = \"Fist_Model\"\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "tag=[tf.compat.v1.saved_model.tag_constants.SERVING]\n",
    "key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7a6ffd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 9s 322ms/step - loss: 0.7231 - accuracy: 0.5875 - val_loss: 0.5423 - val_accuracy: 0.8438\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 8s 300ms/step - loss: 0.5290 - accuracy: 0.7350 - val_loss: 0.3476 - val_accuracy: 0.8646\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 0.4496 - accuracy: 0.8150 - val_loss: 0.3853 - val_accuracy: 0.8021\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 8s 298ms/step - loss: 0.3468 - accuracy: 0.8650 - val_loss: 0.2947 - val_accuracy: 0.8646\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 8s 319ms/step - loss: 0.2896 - accuracy: 0.8925 - val_loss: 0.3550 - val_accuracy: 0.8125\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 7s 291ms/step - loss: 0.2491 - accuracy: 0.9000 - val_loss: 0.3066 - val_accuracy: 0.8646\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 8s 330ms/step - loss: 0.2258 - accuracy: 0.9025 - val_loss: 0.3071 - val_accuracy: 0.8646\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 0.2075 - accuracy: 0.9275 - val_loss: 0.3034 - val_accuracy: 0.8542\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 8s 332ms/step - loss: 0.2042 - accuracy: 0.9150 - val_loss: 0.3529 - val_accuracy: 0.8542\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 8s 300ms/step - loss: 0.2065 - accuracy: 0.9225 - val_loss: 0.3454 - val_accuracy: 0.8438\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 9s 342ms/step - loss: 0.1657 - accuracy: 0.9300 - val_loss: 0.3480 - val_accuracy: 0.8438\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 8s 332ms/step - loss: 0.1969 - accuracy: 0.9250 - val_loss: 0.3663 - val_accuracy: 0.8438\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 9s 362ms/step - loss: 0.1683 - accuracy: 0.9225 - val_loss: 0.4117 - val_accuracy: 0.8229\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 10s 394ms/step - loss: 0.1722 - accuracy: 0.9250 - val_loss: 0.4245 - val_accuracy: 0.8229\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 9s 357ms/step - loss: 0.1414 - accuracy: 0.9400 - val_loss: 0.2679 - val_accuracy: 0.8958\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 8s 332ms/step - loss: 0.1428 - accuracy: 0.9450 - val_loss: 0.2874 - val_accuracy: 0.8854\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 8s 329ms/step - loss: 0.1436 - accuracy: 0.9500 - val_loss: 0.3069 - val_accuracy: 0.8750\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 10s 401ms/step - loss: 0.1309 - accuracy: 0.9500 - val_loss: 0.3179 - val_accuracy: 0.8646\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 10s 378ms/step - loss: 0.1566 - accuracy: 0.9450 - val_loss: 0.2885 - val_accuracy: 0.8542\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 9s 371ms/step - loss: 0.1219 - accuracy: 0.9525 - val_loss: 0.2496 - val_accuracy: 0.9062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model3\\assets\n",
      "2022/10/19 18:49:43 INFO mlflow.tensorflow: Validating the specified TensorFlow model by attempting to load it in a new TensorFlow graph...\n",
      "2022/10/19 18:49:45 INFO mlflow.tensorflow: Validation succeeded!\n",
      "C:\\Users\\med-a\\anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Successfully registered model 'heyhey test'.\n",
      "2022/10/19 18:50:06 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: heyhey test, version 1\n",
      "Created version '1' of model 'heyhey test'.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history=model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)\n",
    "    tf.keras.models.save_model(model,saved_model_path)\n",
    "    mlflow.tensorflow.log_model(tf_saved_model_dir=saved_model_path,\n",
    "                                tf_meta_graph_tags=tag,\n",
    "                                tf_signature_def_key=key,\n",
    "                                artifact_path=saved_model_path,\n",
    "                                registered_model_name=)\n",
    "    for i in history.history:\n",
    "        history.history[i]=history.history[i][-1]\n",
    "    mlflow.log_metrics(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "550b92b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicted Class Planes\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import load_img\n",
    "image = load_img('v_data/test/planes/3.jpg', target_size=(224, 224))\n",
    "img = np.array(image)\n",
    "img = img / 255.0\n",
    "img = img.reshape(1,224,224,3)\n",
    "label = model.predict(img)\n",
    "if (label[0][0]<0.5) and (label[0][1]<0.5) :\n",
    "    print(\"This is NOT a car NOR a plane\")\n",
    "elif label[0][0]<label[0][1]  :\n",
    "    print(\"Predicted Class Planes\")\n",
    "else :\n",
    "    print(\"Predicted Class Cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdb5d357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 8s 280ms/step - loss: 5.5296 - accuracy: 0.5550 - val_loss: 0.6130 - val_accuracy: 0.6979\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.7986 - accuracy: 0.6200 - val_loss: 0.4062 - val_accuracy: 0.8750\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 7s 294ms/step - loss: 0.5677 - accuracy: 0.7350 - val_loss: 0.3636 - val_accuracy: 0.8542\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 8s 299ms/step - loss: 0.4004 - accuracy: 0.8275 - val_loss: 0.3017 - val_accuracy: 0.8542\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 8s 299ms/step - loss: 0.3363 - accuracy: 0.8675 - val_loss: 0.2880 - val_accuracy: 0.8438\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 7s 285ms/step - loss: 0.3152 - accuracy: 0.8475 - val_loss: 0.3213 - val_accuracy: 0.8646\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 7s 286ms/step - loss: 0.2804 - accuracy: 0.8875 - val_loss: 0.2748 - val_accuracy: 0.8542\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 7s 289ms/step - loss: 0.2365 - accuracy: 0.9025 - val_loss: 0.2868 - val_accuracy: 0.8854\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 8s 300ms/step - loss: 0.2986 - accuracy: 0.8850 - val_loss: 0.3269 - val_accuracy: 0.8750\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 8s 308ms/step - loss: 0.2193 - accuracy: 0.9175 - val_loss: 0.3517 - val_accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 8s 316ms/step - loss: 0.2258 - accuracy: 0.9075 - val_loss: 0.4042 - val_accuracy: 0.8542\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 9s 343ms/step - loss: 0.1991 - accuracy: 0.9275 - val_loss: 0.3381 - val_accuracy: 0.8854\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 9s 340ms/step - loss: 0.1768 - accuracy: 0.9350 - val_loss: 0.3372 - val_accuracy: 0.8958\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 9s 350ms/step - loss: 0.1345 - accuracy: 0.9500 - val_loss: 0.3741 - val_accuracy: 0.8646\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 9s 358ms/step - loss: 0.1893 - accuracy: 0.9400 - val_loss: 0.4259 - val_accuracy: 0.8333\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 9s 365ms/step - loss: 0.1457 - accuracy: 0.9525 - val_loss: 0.3840 - val_accuracy: 0.8438\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 9s 352ms/step - loss: 0.1126 - accuracy: 0.9500 - val_loss: 0.3722 - val_accuracy: 0.8542\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 9s 352ms/step - loss: 0.0950 - accuracy: 0.9775 - val_loss: 0.5370 - val_accuracy: 0.8333\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 9s 355ms/step - loss: 0.1155 - accuracy: 0.9500 - val_loss: 0.3940 - val_accuracy: 0.8750\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 9s 350ms/step - loss: 0.0874 - accuracy: 0.9650 - val_loss: 0.4245 - val_accuracy: 0.8958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\med-a\\Desktop\\Img Classification\\Model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\med-a\\Desktop\\Img Classification\\Model1\\assets\n",
      "2022/10/19 16:03:04 INFO mlflow.tensorflow: Validating the specified TensorFlow model by attempting to load it in a new TensorFlow graph...\n",
      "2022/10/19 16:03:05 INFO mlflow.tensorflow: Validation succeeded!\n",
      "Successfully registered model 'Second Model'.\n",
      "2022/10/19 16:03:15 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Second Model, version 1\n",
      "Created version '1' of model 'Second Model'.\n"
     ]
    }
   ],
   "source": [
    "reg_model_name1=\"Second Model\"\n",
    "with mlflow.start_run():\n",
    "    model1 = Sequential()\n",
    "    model1.add(Conv2D(32, (2, 2)))\n",
    "    model1.add(Activation('relu'))\n",
    "    model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model1.add(Dropout(0.2))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(64))\n",
    "    model1.add(Activation('relu'))\n",
    "    model1.add(Dense(32))\n",
    "    model1.add(Activation('relu'))\n",
    "    model1.add(Dropout(0.2))\n",
    "    model1.add(Dense(2))\n",
    "    model1.add(Activation('softmax'))\n",
    "    model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history=model1.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)\n",
    "    tf.keras.models.save_model(model,saved_model_path1)\n",
    "    mlflow.tensorflow.log_model(tf_saved_model_dir=saved_model_path1,\n",
    "                                tf_meta_graph_tags=tag,\n",
    "                                tf_signature_def_key=key,\n",
    "                                artifact_path=saved_model_path1,\n",
    "                                registered_model_name=reg_model_name1)\n",
    "    for i in history.history:\n",
    "        history.history[i]=history.history[i][-1]\n",
    "    mlflow.log_metrics(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25dd9240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 17s 667ms/step - loss: 0.7585 - accuracy: 0.5175 - val_loss: 0.6947 - val_accuracy: 0.4792\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 17s 658ms/step - loss: 0.6941 - accuracy: 0.5200 - val_loss: 0.6888 - val_accuracy: 0.6146\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 17s 686ms/step - loss: 0.6276 - accuracy: 0.6650 - val_loss: 0.5557 - val_accuracy: 0.7917\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 17s 669ms/step - loss: 0.4496 - accuracy: 0.8275 - val_loss: 0.4796 - val_accuracy: 0.7812\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 17s 670ms/step - loss: 0.3687 - accuracy: 0.8550 - val_loss: 0.4744 - val_accuracy: 0.8021\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 17s 669ms/step - loss: 0.3460 - accuracy: 0.8575 - val_loss: 0.4743 - val_accuracy: 0.7708\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 18s 716ms/step - loss: 0.3818 - accuracy: 0.8325 - val_loss: 0.4826 - val_accuracy: 0.8021\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 17s 695ms/step - loss: 0.3082 - accuracy: 0.8975 - val_loss: 0.4114 - val_accuracy: 0.8333\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 17s 677ms/step - loss: 0.2717 - accuracy: 0.8850 - val_loss: 0.4424 - val_accuracy: 0.7917\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 18s 716ms/step - loss: 0.2611 - accuracy: 0.9025 - val_loss: 0.3858 - val_accuracy: 0.8229\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 17s 676ms/step - loss: 0.2456 - accuracy: 0.8775 - val_loss: 0.3781 - val_accuracy: 0.8438\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 17s 673ms/step - loss: 0.2472 - accuracy: 0.8975 - val_loss: 0.3575 - val_accuracy: 0.8750\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 17s 663ms/step - loss: 0.2502 - accuracy: 0.9050 - val_loss: 0.3907 - val_accuracy: 0.8333\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 17s 664ms/step - loss: 0.2053 - accuracy: 0.9200 - val_loss: 0.3520 - val_accuracy: 0.8438\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 18s 700ms/step - loss: 0.1938 - accuracy: 0.9125 - val_loss: 0.3372 - val_accuracy: 0.8646\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 18s 697ms/step - loss: 0.2303 - accuracy: 0.8975 - val_loss: 0.4109 - val_accuracy: 0.8021\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 17s 690ms/step - loss: 0.1906 - accuracy: 0.9250 - val_loss: 0.3198 - val_accuracy: 0.8542\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 17s 682ms/step - loss: 0.1455 - accuracy: 0.9375 - val_loss: 0.3075 - val_accuracy: 0.8750\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 18s 707ms/step - loss: 0.1920 - accuracy: 0.9325 - val_loss: 0.3364 - val_accuracy: 0.8333\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 17s 684ms/step - loss: 0.1800 - accuracy: 0.9425 - val_loss: 0.3263 - val_accuracy: 0.8438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\med-a\\Desktop\\Img Classification\\Model2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\med-a\\Desktop\\Img Classification\\Model2\\assets\n",
      "2022/10/19 16:16:23 INFO mlflow.tensorflow: Validating the specified TensorFlow model by attempting to load it in a new TensorFlow graph...\n",
      "2022/10/19 16:16:25 INFO mlflow.tensorflow: Validation succeeded!\n",
      "Successfully registered model 'Third Model'.\n",
      "2022/10/19 16:16:39 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Third Model, version 1\n",
      "Created version '1' of model 'Third Model'.\n"
     ]
    }
   ],
   "source": [
    "reg_model_name2=\"Third Model\"\n",
    "with mlflow.start_run():\n",
    "    model2 = Sequential()\n",
    "    model2.add(Conv2D(64, (2, 2), input_shape=input_shape))\n",
    "    model2.add(Activation('relu'))\n",
    "    model2.add(Dropout(0.5))\n",
    "    model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model2.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
    "    model2.add(Activation('relu'))\n",
    "    model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model2.add(Dropout(0.2))\n",
    "    model2.add(Conv2D(32, (2, 2)))\n",
    "    model2.add(Activation('relu'))\n",
    "    model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model2.add(Dropout(0.2))\n",
    "    model2.add(Conv2D(64, (2, 2)))\n",
    "    model2.add(Activation('relu'))\n",
    "    model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model2.add(Dropout(0.2))\n",
    "    model2.add(Flatten())\n",
    "    model2.add(Dense(64))\n",
    "    model2.add(Activation('relu'))\n",
    "    model2.add(Dense(32))\n",
    "    model2.add(Activation('relu'))\n",
    "    model2.add(Dropout(0.2))\n",
    "    model2.add(Dense(2))\n",
    "    model2.add(Activation('softmax'))\n",
    "    model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history=model2.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)\n",
    "    tf.keras.models.save_model(model2,saved_model_path2)\n",
    "    mlflow.tensorflow.log_model(tf_saved_model_dir=saved_model_path2,\n",
    "                                tf_meta_graph_tags=tag,\n",
    "                                tf_signature_def_key=key,\n",
    "                                artifact_path=saved_model_path2,\n",
    "                                registered_model_name=reg_model_name2)\n",
    "    for i in history.history:\n",
    "        history.history[i]=history.history[i][-1]\n",
    "    mlflow.log_metrics(history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
